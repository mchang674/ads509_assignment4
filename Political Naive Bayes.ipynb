{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text \n",
    "for each party and prepare it for use in Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill the above list up with items that are themselves lists. The \n",
    "# sublists will have two elements. The first element in the sublist\n",
    "# should be the speech in a single string. The second element\n",
    "# of the sublist should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT party, text FROM conventions\n",
    "                            where party != \"Other\"\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    # store the results in convention_data\n",
    "    # remove this and replace with your code\n",
    "    party = row[0]\n",
    "    speech = row[1]\n",
    "    convention_data.append([speech, party])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a best practice to close up your DB connection when you're done\n",
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['And now, we’ll hear from Kristin Urquiza.', 'Democratic'],\n",
       " ['In my husband, you have a president who will not stop fighting for you and your families. I see how hard he works each day and night, and despite the unprecedented attacks from the media and opposition, he will not give up. In fact, if you tell him he cannot be done, he just works harder. Donald is a husband who supports me in all that I do. He has built an administration with an unprecedented number of women in leadership roles, and has fostered an environment where the American people are always the priority. He welcomes different points of view and encourage thinking outside of the box. I know I speak for my husband and the family when I say we are so grateful that you have trusted him to be your president, and we will be honored to serve this incredible country for four more years. As you have heard this evening, I don’t want to use this precious time attacking the other side, because as we saw last week, that kind of talk only serves to divide the country further. I’m here because we need my husband to be our president and commander-in-chief for four more years. He’s what is best for our country. We all know Donald Trump makes no secrets about how he feels about things. Total honesty is what we as citizens deserve from our president. Whether you like it or not, you always know what he’s thinking, and that is because he’s an authentic person who loves this country and its people and wants to continue to make it better. Donald wants to keep your family safe. He wants to help your family succeed. He wants nothing more than for this country to prosper, and he doesn’t waste time playing politics.',\n",
       "  'Republican'],\n",
       " ['Dan tell me a little bit about the farm.', 'Democratic'],\n",
       " ['What this administration has done, simplifying the government, it’s really cut the handcuffs off of America again and allowed us to grow and move forward in a way that I have never seen in my lifetime.',\n",
       "  'Republican'],\n",
       " ['Well, you beat Hodgkin’s lymphoma. God love you. But during it all, Trump was trying to rip away your coverage. The day you got your first chemo, Republicans voted to gut the ACA. I can’t imagine what it must’ve been like going to sleep at night, wondering what to do.',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be useful for us to have a large sample size than 2024 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_sent_data = []\n",
    "\n",
    "for speech, party in convention_data :\n",
    "    first = nltk.sent_tokenize(speech)[0]\n",
    "    conv_sent_data.append([first, party])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's look at some random entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['So today, six months after it began, the nation is still unprepared.',\n",
       "  'Democratic'],\n",
       " ['How long was your problem.', 'Republican'],\n",
       " ['Good evening.', 'Republican'],\n",
       " ['These women and the generations that followed worked to make democracy and opportunity real in the lives of all of us who followed.',\n",
       "  'Democratic'],\n",
       " ['The child who knows that black lives matter.', 'Democratic']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps: \n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['allegiance fidelity', 'Republican'],\n",
       " ['know typical former surgeon general speak convention', 'Democratic'],\n",
       " ['reverend kind know like lose family heart goes', 'Democratic'],\n",
       " ['indiana', 'Democratic'],\n",
       " ['knows saving planet', 'Democratic']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_conv_sent_data = [] # list of tuples (sentence, party), with sentence cleaned\n",
    "\n",
    "for idx, sent_party in conv_sent_data :\n",
    "    tokens = word_tokenize(idx)\n",
    "    tokens = [token for token in tokens if token not in punctuation]\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    sent = ' '.join(tokens)\n",
    "    clean_conv_sent_data.append([sent, sent_party])\n",
    "    \n",
    "    \n",
    "\n",
    "random.choices(clean_conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 628 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,feature_words) :\n",
    "     ret_dict = dict()\n",
    "     word = text.split()\n",
    "     ret_dict = {word: True for word in word if word in feature_words}\n",
    "     return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"obama was the president\",feature_words)==\n",
    "       {'obama':True,'president':True})\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             enforcement = True           Republ : Democr =     27.5 : 1.0\n",
      "                   votes = True           Democr : Republ =     21.6 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.3 : 1.0\n",
      "                   media = True           Republ : Democr =     15.9 : 1.0\n",
      "              appreciate = True           Republ : Democr =     14.0 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.3 : 1.0\n",
      "                 special = True           Republ : Democr =     10.3 : 1.0\n",
      "                   local = True           Republ : Democr =      9.9 : 1.0\n",
      "                   elect = True           Democr : Republ =      9.6 : 1.0\n",
      "                    land = True           Republ : Democr =      8.9 : 1.0\n",
      "                  cities = True           Republ : Democr =      8.4 : 1.0\n",
      "                citizens = True           Republ : Democr =      8.4 : 1.0\n",
      "                    flag = True           Republ : Democr =      8.4 : 1.0\n",
      "                greatest = True           Republ : Democr =      8.4 : 1.0\n",
      "                   clean = True           Democr : Republ =      7.9 : 1.0\n",
      "                 freedom = True           Republ : Democr =      7.8 : 1.0\n",
      "                     law = True           Republ : Democr =      7.8 : 1.0\n",
      "                  senior = True           Republ : Democr =      7.8 : 1.0\n",
      "                  record = True           Republ : Democr =      7.3 : 1.0\n",
      "                officers = True           Republ : Democr =      7.2 : 1.0\n",
      "                grateful = True           Republ : Democr =      6.9 : 1.0\n",
      "                    grew = True           Republ : Democr =      6.9 : 1.0\n",
      "                  heroes = True           Republ : Democr =      6.8 : 1.0\n",
      "                  border = True           Republ : Democr =      6.7 : 1.0\n",
      "                    race = True           Republ : Democr =      6.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "It seems that the words \"encorcement\", \"media\", \"appreciate\", \"drug\", \"special\" and \"local\" are the words that indicate to this model that a speech is done by a Republican. The words \"votes\", \"climate\", \"elect\", and \"clean\" are the words that the model finds most important for classifying a speech is done by a Democrat. There seem to be a lot more words that indicate a Republican speech over a Democrat speech than vice versa. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "for row in results :\n",
    "    # store the results in convention_data\n",
    "    # remove this and replace with your code\n",
    "    candidate = row[0]\n",
    "    party = row[1]\n",
    "    tweet = row[2]\n",
    "    tweet_data.append([tweet, party])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20250602)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimator(text):\n",
    "    features = conv_features(str(text),feature_words) \n",
    "    est = classifier.classify(features)\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: b\"Enjoyed updating the Mount Ayr Chamber of Commerce on what I've been working on in Congress. #IA03 https://t.co/74iEFpwkL5\"\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Coming to you live from the Basalt town hall with Rep. Hamner https://t.co/Cstsx9NeP0'\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: b'A citizen was shot by Park Police officers. The authorities won\\xe2\\x80\\x99t say why.\\n\\nThank you @washingtonpost @PostOpinions for pressing the FBI to deliver answers about the killing of Bijan Ghaisar. His family has been denied justice for far too long. https://t.co/nnXA2XWXam'\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Sandy Hook Elementary School prepping to join the #Monroe Memorial Day Parade. https://t.co/cYiB3Le86K'\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"Our press release on Sen. Rod Grams' endorsement: http://bit.ly/cKTB6d #mn2010 #mngov\"\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: b'@josh_crownover You are welcome to video. Sorry I didn\\xe2\\x80\\x99t reply last night. I go to bed right at 10:00 (most nights). Hope to see you there.'\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Excited for lunch tomorrow at Graze on Main in Wytheville to hear @MarkWarner congratulate and honor local businesses!'\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Wayne &amp; Barbara Owens spoke of their son Derrick, a police officer killed in duty &amp; loving dad #ImWithHer https://t.co/WI0UTyHaUA'\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: b\"5/ I still believe ICE and CBP must be reformed to reflect our values, our Constitutional principles, and basic human dignity. \\n\\nI also believe politicians shouldn't treat issues of life, death, and dignity so flippantly - or just for political gain.\\n\\nhttps://t.co/FZtMdaiZ16\"\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: b'Pathetic: @realDonaldTrump/@FoxNews trying to marginalize the activism of millions w/ phony \"paid\" accusations. #SMH https://t.co/DyL65P1tCL'\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = estimator(tweet)\n",
    "    \n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    party = party\n",
    "    estimated_party = estimator(tweet)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 2431, 'Democratic': 1905}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 3448, 'Democratic': 2218})})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "act_R",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "act_D",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "473844b2-4657-4d07-9676-7d923c440d29",
       "rows": [
        [
         "est_R",
         "2431",
         "3448"
        ],
        [
         "est_D",
         "1905",
         "2218"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_R</th>\n",
       "      <th>act_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>est_R</th>\n",
       "      <td>2431</td>\n",
       "      <td>3448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>est_D</th>\n",
       "      <td>1905</td>\n",
       "      <td>2218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       act_R  act_D\n",
       "est_R   2431   3448\n",
       "est_D   1905   2218"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.columns = ['act_R', 'act_D']\n",
    "df.set_axis(['est_R', 'est_D'], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46480703859228156"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2431+2218)/(2431+2218+1905+3448)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "The classifier got a 46% accuracy, which is similar to the 49% from the speech model. The model made the most mistakes labelling tweets made by Democratic members as  \"Republican\". The model made the least mistakes labelling Republican-made tweets as Democrat-made tweets. This would seem to indicate that Republicans use language in their tweets that is more distinct to the Republican party than Democrats. However, I would be cautious in drawing any conclusions from this data, given the fact that its accuracy is worse than the flip of a coin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
