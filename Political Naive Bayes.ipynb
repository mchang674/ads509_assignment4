{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text \n",
    "for each party and prepare it for use in Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill the above list up with items that are themselves lists. The \n",
    "# sublists will have two elements. The first element in the sublist\n",
    "# should be the speech in a single string. The second element\n",
    "# of the sublist should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT party, text FROM conventions\n",
    "                            where party != \"Other\"\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    # store the results in convention_data\n",
    "    # remove this and replace with your code\n",
    "    party = row[0]\n",
    "    speech = row[1]\n",
    "    convention_data.append([speech, party])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a best practice to close up your DB connection when you're done\n",
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hi, I’m Susan Molinari. I’m a former Republican member of Congress from New York City, and I’ve known Donald Trump for most of my political career. So disappointing and lately, so disturbing. Now, I’ve also gotten to know and work with Joe Biden on issues related to women that are so important to all of us, women in business violence against women. That’s why I’m so proud to call him my friend, and honored to join and supporting his candidacy for president. He’s a really good man and he’s exactly what this nation needs at this time. Now I’m delighted and honored to introduce a former colleague of mine, the former Congressman from Ohio, the former Governor of Ohio, John Kasich.',\n",
       "  'Democratic'],\n",
       " ['This time next year.', 'Democratic'],\n",
       " ['Joe’s working to protect and expand the Affordable Care Act to make sure millions of people keep their coverage and no one can be denied for a pre-existing condition. To bring down the costs of healthcare and prescription drugs too, giving tax credits to working families and allowing Medicare to negotiate drug prices.',\n",
       "  'Democratic'],\n",
       " ['Our military is now better equipped, better resourced and better manned than any military in the world. President Trump demolished the terrorist ISIS caliphate in the Middle East and eliminated its leader, al-Baghdadi, one of the world’s most brutal terrorists. President Trump took decisive action against Iranian terrorist mastermind, Qasem Soleimani, a man responsible for deaths of hundreds of American service men in Iraq. When our NATO allies failed to meet their commitments, as we upheld ours, President Trump demanded parody. NATO members have now increased their contributions over $100 billion this year, and NATO’s secretary general credits President Donald J. Trump.',\n",
       "  'Republican'],\n",
       " ['People must recognize that our thoughts, our opinions, and even the choice of who we are voting for may and are being manipulated and visibly coerced by the media and tech giants. If you tune into the media, you get one biased opinion or another, and what you share, if it does not fit into the narrative that they seek to promote, then it is either ignored or deemed a lie, regardless of the truth. This manipulation of what information we receive impedes our freedoms, rather than allowing Americans the right to form our own beliefs, this misinformation system keeps people mentally enslaved to the ideas they deem correct. This has fostered unnecessary fear and divisiveness amongst us. Why are so many in media and technology and even in our own government so invested in promoting a biased and fabricated view? Ask yourselves, why are we prevented from seeing certain information? Why is one viewpoint promoted while others are hidden? The answer is control, because division and controversy breed profit.',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be useful for us to have a large sample size than 2024 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_sent_data = []\n",
    "\n",
    "for speech, party in convention_data :\n",
    "    first = nltk.sent_tokenize(speech)[0]\n",
    "    conv_sent_data.append([first, party])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's look at some random entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['And then there’s Pastor Aaron Johnson.', 'Republican'],\n",
       " ['That I absolutely and entirely.', 'Republican'],\n",
       " ['President Trump will rebuild America’s infrastructure, renew hope, and our entrepreneurial spirit for a new generation, and restore the American dream.',\n",
       "  'Republican'],\n",
       " ['He will make it his job to know when anyone dares to threaten us, he will stand up to our adversaries with strength and experience.',\n",
       "  'Democratic'],\n",
       " ['My name is Abby Johnson, and I spent eight years working for Planned Parenthood, but today I’m a pro-life activist.',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps: \n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['han grew poverty immigrants able make decent living', 'Democratic'],\n",
       " ['something wrong', 'Democratic'],\n",
       " ['seen tragic shootings sides officers killing citizens citizens killing officers line duty',\n",
       "  'Republican'],\n",
       " ['human cost devastating', 'Republican'],\n",
       " ['give children children children planet sustain', 'Democratic']]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_conv_sent_data = [] # list of tuples (sentence, party), with sentence cleaned\n",
    "\n",
    "for idx, sent_party in conv_sent_data :\n",
    "    tokens = word_tokenize(idx)\n",
    "    tokens = [token for token in tokens if token not in punctuation]\n",
    "    tokens = [token for token in tokens if token.isalpha()]\n",
    "    tokens = [token for token in tokens if token.lower() not in stopwords]\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    sent = ' '.join(tokens)\n",
    "    clean_conv_sent_data.append([sent, sent_party])\n",
    "    \n",
    "    \n",
    "\n",
    "random.choices(clean_conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 628 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in clean_conv_sent_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,feature_words) :\n",
    "     ret_dict = dict()\n",
    "     word = text.split()\n",
    "     ret_dict = {word: True for word in word if word in feature_words}\n",
    "     return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"obama was the president\",feature_words)==\n",
    "       {'obama':True,'president':True})\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.494\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             enforcement = True           Republ : Democr =     27.5 : 1.0\n",
      "                   votes = True           Democr : Republ =     21.6 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.3 : 1.0\n",
      "                   media = True           Republ : Democr =     15.9 : 1.0\n",
      "              appreciate = True           Republ : Democr =     14.0 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.3 : 1.0\n",
      "                 special = True           Republ : Democr =     10.3 : 1.0\n",
      "                   local = True           Republ : Democr =      9.9 : 1.0\n",
      "                   elect = True           Democr : Republ =      9.6 : 1.0\n",
      "                    land = True           Republ : Democr =      8.9 : 1.0\n",
      "                  cities = True           Republ : Democr =      8.4 : 1.0\n",
      "                citizens = True           Republ : Democr =      8.4 : 1.0\n",
      "                    flag = True           Republ : Democr =      8.4 : 1.0\n",
      "                greatest = True           Republ : Democr =      8.4 : 1.0\n",
      "                   clean = True           Democr : Republ =      7.9 : 1.0\n",
      "                 freedom = True           Republ : Democr =      7.8 : 1.0\n",
      "                     law = True           Republ : Democr =      7.8 : 1.0\n",
      "                  senior = True           Republ : Democr =      7.8 : 1.0\n",
      "                  record = True           Republ : Democr =      7.3 : 1.0\n",
      "                officers = True           Republ : Democr =      7.2 : 1.0\n",
      "                grateful = True           Republ : Democr =      6.9 : 1.0\n",
      "                    grew = True           Republ : Democr =      6.9 : 1.0\n",
      "                  heroes = True           Republ : Democr =      6.8 : 1.0\n",
      "                  border = True           Republ : Democr =      6.7 : 1.0\n",
      "                    race = True           Republ : Democr =      6.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "It seems that the words \"encorcement\", \"media\", \"appreciate\", \"drug\", \"special\" and \"local\" are the words that indicate to this model that a speech is done by a Republican. The words \"votes\", \"climate\", \"elect\", and \"clean\" are the words that the model finds most important for classifying a speech is done by a Democrat. There seem to be a lot more words that indicate a Republican speech over a Democrat speech than vice versa. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "for row in results :\n",
    "    # store the results in convention_data\n",
    "    # remove this and replace with your code\n",
    "    candidate = row[0]\n",
    "    party = row[1]\n",
    "    tweet = row[2]\n",
    "    tweet_data.append([tweet, party])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20250602)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = nltk.NaiveBayesClassifier.train(featuresets)\n",
    "featuresets2 = [(conv_features(text,feature_words), party) for (text, party) in tweet_data_sample]\n",
    "\n",
    "def estimator(index):\n",
    "    est = classifier2.classify(featuresets2[index])\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[224], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m test_set, train_set \u001b[38;5;241m=\u001b[39m featuresets2[:test_size], featuresets2[test_size:]\n\u001b[1;32m      3\u001b[0m classifier2 \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mNaiveBayesClassifier\u001b[38;5;241m.\u001b[39mtrain(train_set)\n\u001b[0;32m----> 4\u001b[0m classifier2\u001b[38;5;241m.\u001b[39mclassify(\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthe country is in danger\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "test_size = 3\n",
    "test_set, train_set = featuresets2[:test_size], featuresets2[test_size:]\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "classifier2.classify(nltk.tokenize('the country is in danger'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = ##\n",
    "    \n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = \"Gotta fill this in\"\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Write a little about what you see in the results_ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
